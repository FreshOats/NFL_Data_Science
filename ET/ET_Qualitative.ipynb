{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and Transform the Injury and Concussion Data\n",
    "This will contain all of the functions for both injury and concussion and list the .py files that they are contained in. Finally, these .py files will be used to actually process the data, NOT the cells within the Jupyter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(dataset): \n",
    "    \"\"\"\n",
    "    Accepts the desired dataset string and opens the file as either a polars dataframe\n",
    "    or a lazyframe. Lazyloading is used for the larger tracking datasets. \n",
    "    \"\"\"\n",
    "    import polars as pl  # type: ignore\n",
    "    import numpy as np # type: ignore\n",
    "\n",
    "    valid_datasets = ['plays', 'injuries', 'role_data', 'punt_data', 'play_information', 'game_data', 'video_review']\n",
    "    if dataset not in valid_datasets: \n",
    "        raise ValueError(f\"Invalid dataset name '{dataset}'. Valid options are: {valid_datasets}\")\n",
    "\n",
    "    try:\n",
    "        # Injury Datasets\n",
    "        if dataset == 'plays':\n",
    "            PlayList_path = \"F:/Data/nfl-playing-surface-analytics/PlayList.csv\"\n",
    "            df = pl.read_csv(PlayList_path)\n",
    "        elif dataset == 'injuries':\n",
    "            InjuryRecord_path = \"F:/Data/nfl-playing-surface-analytics/InjuryRecord.csv\"\n",
    "            df = pl.read_csv(InjuryRecord_path)\n",
    "\n",
    "        # Concussion Datasets\n",
    "        elif dataset == 'role_data':\n",
    "            play_player_role_data_path = \"F:/Data/NFL-Punt-Analytics-Competition/play_player_role_data.csv\"\n",
    "            df = pl.read_csv(play_player_role_data_path)\n",
    "        elif dataset == 'punt_data':\n",
    "            player_punt_data_path = \"F:/Data/NFL-Punt-Analytics-Competition/player_punt_data.csv\"\n",
    "            df = pl.read_csv(player_punt_data_path)\n",
    "        elif dataset == 'play_information':\n",
    "            play_information_path = \"F:/Data/NFL-Punt-Analytics-Competition/play_information.csv\"\n",
    "            df = pl.read_csv(play_information_path)\n",
    "        elif dataset == 'game_data':\n",
    "            game_data_path = \"F:/Data/NFL-Punt-Analytics-Competition/game_data.csv\"\n",
    "            df = pl.read_csv(game_data_path)\n",
    "        elif dataset == 'video_review':\n",
    "            video_review_path = \"F:/Data/NFL-Punt-Analytics-Competition/video_review.csv\"\n",
    "            df = pl.read_csv(video_review_path)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(f\"An error occurred while loading the dataset '{dataset}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_joiner(analysis):\n",
    "    \"\"\"\n",
    "    Joins the two non-ngs tables in the injury data, and joins 5 non-ngs tables from the concussion dataset. \n",
    "    \"\"\"\n",
    "    import polars as pl # type: ignore\n",
    "    # from DataHandler import data_loader\n",
    "\n",
    "    valid_analyses = ['injury', 'concussion']\n",
    "    if analysis not in valid_analyses: \n",
    "        raise ValueError(f\"Invalid dataset name '{analysis}'. Valid options are: {valid_analyses}\")\n",
    "\n",
    "\n",
    "    try: \n",
    "        #Injury Data Loader\n",
    "        if analysis == 'injury':\n",
    "            plays = data_loader('plays')\n",
    "            injuries = data_loader('injuries')\n",
    "\n",
    "            df = (\n",
    "                plays.join(injuries, on=\"PlayKey\", how='left')\n",
    "                .select([\n",
    "                    pl.col(\"PlayKey\").cast(pl.Utf8)\n",
    "                    , pl.col(\"Position\").cast(pl.Utf8)\n",
    "                    , pl.col(\"StadiumType\").cast(pl.Utf8)\n",
    "                    , pl.col(\"FieldType\").cast(pl.Utf8)\n",
    "                    , pl.col(\"Temperature\").cast(pl.Int16)\n",
    "                    , pl.col(\"Weather\").cast(pl.Utf8)\n",
    "                    , pl.col(\"PlayType\").cast(pl.Utf8)\n",
    "                    , pl.col(\"BodyPart\").cast(pl.Utf8)\n",
    "                    , pl.col(\"DM_M1\").cast(pl.Int8)\n",
    "                    , pl.col(\"DM_M7\").cast(pl.Int8)\n",
    "                    , pl.col(\"DM_M28\").cast(pl.Int8)\n",
    "                    , pl.col(\"DM_M42\").cast(pl.Int8)\n",
    "                ])\n",
    "            )\n",
    "\n",
    "        # Concussion Data Loader\n",
    "        elif analysis == 'concussion':\n",
    "            role_data = data_loader('role_data')\n",
    "            punt_data = data_loader('punt_data')\n",
    "            play_information = data_loader('play_information')\n",
    "            game_data = data_loader('game_data')\n",
    "            video_review = data_loader('video_review')\n",
    "\n",
    "\n",
    "            df = (\n",
    "                role_data\n",
    "                .join(\n",
    "                    punt_data\n",
    "                    , left_on=\"GSISID\"\n",
    "                    , right_on=\"GSISID\"\n",
    "                    , how=\"left\"\n",
    "                    , suffix=\"_punt\"\n",
    "                )\n",
    "                .join(\n",
    "                    play_information\n",
    "                    , left_on=[\"GameKey\", \"PlayID\"]\n",
    "                    , right_on=[\"GameKey\", \"PlayID\"]\n",
    "                    , how=\"left\"\n",
    "                    , suffix=\"_play\"\n",
    "                )\n",
    "                .join(\n",
    "                    game_data\n",
    "                    , left_on=\"GameKey\"\n",
    "                    , right_on=\"GameKey\"\n",
    "                    , how=\"left\"\n",
    "                    , suffix=\"_game\"\n",
    "                )\n",
    "                .join(\n",
    "                    video_review\n",
    "                    , left_on=[\"GameKey\", \"PlayID\", \"GSISID\"]\n",
    "                    , right_on=[\"GameKey\", \"PlayID\", \"GSISID\"]\n",
    "                    , how=\"left\"\n",
    "                    , suffix=\"_video\"\n",
    "                )\n",
    "                .with_columns([\n",
    "                    pl.concat_str([\n",
    "                        pl.col(\"GSISID\").cast(pl.Utf8)\n",
    "                        , pl.lit(\"-\")\n",
    "                        , pl.col(\"GameKey\").cast(pl.Utf8)\n",
    "                        , pl.lit(\"-\")\n",
    "                        , pl.col(\"PlayID\").cast(pl.Utf8)\n",
    "                    ]).alias(\"PlayKey\"),\n",
    "                    pl.concat_str([\n",
    "                        pl.col(\"Primary_Partner_GSISID\").cast(pl.Utf8)\n",
    "                        , pl.lit(\"-\")\n",
    "                        , pl.col(\"GameKey\").cast(pl.Utf8)\n",
    "                        , pl.lit(\"-\")\n",
    "                        , pl.col(\"PlayID\").cast(pl.Utf8)\n",
    "                    ]).alias(\"OpponentKey\")\n",
    "                    , pl.when(pl.col(\"Primary_Partner_GSISID\") == \"Unclear\")\n",
    "                        .then(pl.lit(\"00000\"))\n",
    "                        .otherwise(pl.col(\"Primary_Partner_GSISID\"))\n",
    "                        .cast(pl.Int64)\n",
    "                        .alias(\"Primary_Partner_GSISID\")\n",
    "                ])\n",
    "                .select([\n",
    "                    \"PlayKey\"\n",
    "                    , \"GSISID\"\n",
    "                    , \"GameKey\"\n",
    "                    , \"PlayID\"\n",
    "                    , \"Position\"\n",
    "                    , 'Number'\n",
    "                    , \"Role\"\n",
    "                    , \"Game_Date\"\n",
    "                    , \"YardLine\"\n",
    "                    , \"Quarter\"\n",
    "                    , \"Play_Type\"\n",
    "                    , \"Poss_Team\"\n",
    "                    , \"Score_Home_Visiting\"\n",
    "                    , \"Game_Site\"\n",
    "                    , \"Start_Time\"\n",
    "                    , \"HomeTeamCode\"\n",
    "                    , \"VisitTeamCode\"\n",
    "                    , \"StadiumType\"\n",
    "                    , \"Turf\"\n",
    "                    , \"GameWeather\"\n",
    "                    , \"Temperature\"\n",
    "                    , \"Player_Activity_Derived\"\n",
    "                    , \"Primary_Impact_Type\"\n",
    "                    , \"Primary_Partner_Activity_Derived\"\n",
    "                    , \"Primary_Partner_GSISID\"\n",
    "                    , \"OpponentKey\"\n",
    "                ])\n",
    "                .unique()\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Tables are holding hands. How cute.\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(f\"An error occurred while processing the '{analysis}' analysis: {e}.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def injury_interpolator(df, analysis): \n",
    "    \"\"\"\n",
    "    Creates two new columns, IsInjured and IsSevere, where any injury sets \n",
    "    IsInjured to 1, and any injury over 28 days provides a 1 in IsSevere\n",
    "    \"\"\"\n",
    "    import polars as pl\n",
    "\n",
    "    if analysis == 'injury':\n",
    "        df = df.with_columns([ \n",
    "            pl.when(pl.col(\"DM_M1\") == 1).then(1).otherwise(0).cast(pl.Int8).alias(\"IsInjured\")\n",
    "            , pl.when(pl.col(\"DM_M28\") == 1).then(1).otherwise(0).cast(pl.Int8).alias(\"IsSevere\")\n",
    "            ])\n",
    "        \n",
    "        df = df.filter(pl.col('PlayType').is_not_null()) # 0.14% of rows did not have a play type, and ALL of these were non-injury plays, so they were removed\n",
    "        df = df.with_columns([ \n",
    "                pl.col(\"BodyPart\").fill_null(\"No_Injury\")\n",
    "                , pl.col([\"DM_M1\", \"DM_M7\", \"DM_M28\", \"DM_M42\"]).fill_null(0)\n",
    "                ])\n",
    "\n",
    "    elif analysis == 'concussion':\n",
    "        df = df.with_columns([ \n",
    "            pl.when(pl.col(\"Primary_Impact_Type\").is_not_null()).then(1).otherwise(0).alias(\"IsInjured\")\n",
    "            , pl.col(\"Player_Activity_Derived\").fill_null(\"No_Injury\")\n",
    "            , pl.col(\"Primary_Impact_Type\").fill_null(\"No_Injury\")\n",
    "            , pl.col(\"Primary_Partner_Activity_Derived\").fill_null(\"No_Injury\")\n",
    "            , pl.col(\"Primary_Partner_GSISID\").fill_null(00000)\n",
    "            , pl.col(\"OpponentKey\").fill_null(\"None\")\n",
    "            ])\n",
    "        \n",
    "    print(\"Injury columns have been added.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stadium_cleaner(df):\n",
    "    \"\"\"\n",
    "    Noramlizes all stadium types to be either indoor or outdoor per game records. Some of the dome \n",
    "    stadiums were listed as open or closed for different games, and these were accounted for.\n",
    "    All games with dates were checked to ensure null values were indeed outdoor games. \n",
    "    \"\"\"\n",
    "    import polars as pl  # type: ignore\n",
    "\n",
    "    stadium_dict = {\n",
    "        'Outdoor': 'Outdoor'\n",
    "        , 'Indoors': 'Indoor'\n",
    "        , 'Oudoor': 'Outdoor'\n",
    "        , 'Outdoors': 'Outdoor'\n",
    "        , 'Open': 'Outdoor'\n",
    "        , 'Closed Dome': 'Indoor'\n",
    "        , 'Domed, closed': 'Indoor'\n",
    "        , 'Dome': 'Indoor'\n",
    "        , 'Indoor': 'Indoor'\n",
    "        , 'Domed': 'Indoor'\n",
    "        , 'Retr. Roof-Closed': 'Indoor'\n",
    "        , 'Outdoor Retr Roof-Open': 'Outdoor'\n",
    "        , 'Retractable Roof': 'Indoor'\n",
    "        , 'Ourdoor': 'Outdoor'\n",
    "        , 'Indoor, Roof Closed': 'Indoor'\n",
    "        , 'Retr. Roof - Closed': 'Indoor'\n",
    "        , 'Bowl': 'Outdoor'\n",
    "        , 'Outddors': 'Outdoor'\n",
    "        , 'Retr. Roof-Open': 'Outdoor'\n",
    "        , 'Dome, closed': 'Indoor'\n",
    "        , 'Indoor, Open Roof': 'Outdoor'\n",
    "        , 'Domed, Open': 'Outdoor'\n",
    "        , 'Domed, open': 'Outdoor'\n",
    "        , 'Heinz Field': 'Outdoor'\n",
    "        , 'Cloudy': 'Outdoor'\n",
    "        , 'Retr. Roof - Open': 'Outdoor'\n",
    "        , 'Retr. Roof Closed': 'Indoor'\n",
    "        , 'Outdor': 'Outdoor'\n",
    "        , 'Outside': 'Outdoor'\n",
    "        , 'outdoor': 'Outdoor'\n",
    "        , 'Outdoors ': 'Outdoor'\n",
    "        , 'Indoor, non-retractable roof': 'Indoor'\n",
    "        , 'Retr. roof - closed': 'Indoor'\n",
    "        , 'Indoor, fixed roof ': 'Indoor'\n",
    "        , 'Indoor, Non-Retractable Dome': 'Indoor'\n",
    "        , 'Indoor, Fixed Roof': 'Indoor'\n",
    "        , 'Indoor, fixed roof': 'Indoor'\n",
    "        , 'Indoors (Domed)': 'Indoor'\n",
    "        , None: 'Outdoor'\n",
    "        }\n",
    "\n",
    "\n",
    "    df = df.with_columns(pl.col(\"StadiumType\").replace(stadium_dict)) # This uses the dict to assign naming conventions\n",
    "\n",
    "    print(f\"Someone managed to clean up those stadiums!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_cleaner(df):\n",
    "     \"\"\"\n",
    "     Uses mapping to limit the number of different weather groupings. \n",
    "     \"\"\"\n",
    "     import polars as pl # type: ignore\n",
    "\n",
    "     # If using the concussion dataset, rename the GameWeather column to Weather\n",
    "     if \"GameWeather\" in df.columns:\n",
    "       df = df.rename({\"GameWeather\": \"Weather\"})\n",
    "\n",
    "     weather_dict = {\n",
    "            'Clear and warm': 'Clear'\n",
    "            , 'Mostly Cloudy': 'Cloudy'\n",
    "            , 'Sunny': 'Clear'\n",
    "            , 'Clear': 'Clear'\n",
    "            , 'Cloudy': 'Cloudy'\n",
    "            , 'Cloudy, fog started developing in 2nd quarter': 'Hazy/Fog'\n",
    "            , 'Rain': 'Rain'\n",
    "            , 'Partly Cloudy': 'Cloudy'\n",
    "            , 'Mostly cloudy': 'Cloudy'\n",
    "            , 'Cloudy and cold': 'Cloudy'\n",
    "            , 'Cloudy and Cool': 'Cloudy'\n",
    "            , 'Rain Chance 40%': 'Rain'\n",
    "            , 'Controlled Climate': 'Indoor'\n",
    "            , 'Sunny and warm': 'Clear'\n",
    "            , 'Partly cloudy': 'Cloudy'\n",
    "            , 'Clear and Cool': 'Cloudy'\n",
    "            , 'Clear and cold': 'Cloudy'\n",
    "            , 'Sunny and cold': 'Clear'\n",
    "            , 'Indoor': 'Indoor'\n",
    "            , 'Partly Sunny': 'Clear'\n",
    "            , 'N/A (Indoors)': 'Indoor'\n",
    "            , 'Mostly Sunny': 'Clear'\n",
    "            , 'Indoors': 'Indoor'\n",
    "            , 'Clear Skies': 'Clear'\n",
    "            , 'Partly sunny': 'Clear'\n",
    "            , 'Showers': 'Rain'\n",
    "            , 'N/A Indoor': 'Indoor'\n",
    "            , 'Sunny and clear': 'Clear'\n",
    "            , 'Snow': 'Snow'\n",
    "            , 'Scattered Showers': 'Rain'\n",
    "            , 'Party Cloudy': 'Cloudy'\n",
    "            , 'Clear skies': 'Clear'\n",
    "            , 'Rain likely, temps in low 40s.': 'Rain'\n",
    "            , 'Hazy': 'Hazy/Fog'\n",
    "            , 'Partly Clouidy': 'Cloudy'\n",
    "            , 'Sunny Skies': 'Clear'\n",
    "            , 'Overcast': 'Cloudy'\n",
    "            , 'Cloudy, 50% change of rain': 'Cloudy'\n",
    "            , 'Fair': 'Clear'\n",
    "            , 'Light Rain': 'Rain'\n",
    "            , 'Partly clear': 'Clear'\n",
    "            , 'Mostly Coudy': 'Cloudy'\n",
    "            , '10% Chance of Rain': 'Cloudy'\n",
    "            , 'Cloudy, chance of rain': 'Cloudy'\n",
    "            , 'Heat Index 95': 'Clear'\n",
    "            , 'Sunny, highs to upper 80s': 'Clear'\n",
    "            , 'Sun & clouds': 'Cloudy'\n",
    "            , 'Heavy lake effect snow': 'Snow'\n",
    "            , 'Mostly sunny': 'Clear'\n",
    "            , 'Cloudy, Rain': 'Rain'\n",
    "            , 'Sunny, Windy': 'Windy'\n",
    "            , 'Mostly Sunny Skies': 'Clear'\n",
    "            , 'Rainy': 'Rain'\n",
    "            , '30% Chance of Rain': 'Rain'\n",
    "            , 'Cloudy, light snow accumulating 1-3\"': 'Snow'\n",
    "            , 'cloudy': 'Cloudy'\n",
    "            , 'Clear and Sunny': 'Clear'\n",
    "            , 'Coudy': 'Cloudy'\n",
    "            , 'Clear and sunny': 'Clear'\n",
    "            , 'Clear to Partly Cloudy': 'Clear'\n",
    "            , 'Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.': 'Windy'\n",
    "            , 'Rain shower': 'Rain'\n",
    "            , 'Cold': 'Clear'\n",
    "            , 'Partly cloudy, lows to upper 50s.': 'Cloudy'\n",
    "            , 'Scattered thunderstorms': 'Rain'\n",
    "            , 'CLEAR': 'Clear'\n",
    "            , 'Partly CLoudy': 'Cloudy'\n",
    "            , 'Chance of Showers': 'Rain'\n",
    "            , 'Snow showers': 'Snow'\n",
    "            , 'Clear and Cold': 'Clear'\n",
    "            , 'Cloudy with rain': 'Rain'\n",
    "            , 'Sunny intervals': 'Clear'\n",
    "            , 'Clear and cool': 'Clear'\n",
    "            , 'Cloudy, Humid, Chance of Rain': 'Rain'\n",
    "            , 'Cloudy and Cold': 'Cloudy'\n",
    "            , 'Cloudy with patches of fog': 'Hazy/Fog'\n",
    "            , 'Controlled': 'Indoor'\n",
    "            , 'Sunny and Clear': 'Clear'\n",
    "            , 'Cloudy with Possible Stray Showers/Thundershowers': 'Rain'\n",
    "            , 'Suny': 'Clear'\n",
    "            , 'T-Storms': 'Rain'\n",
    "            , 'Sunny and cool': 'Clear'\n",
    "            , 'Cloudy, steady temps': 'Cloudy'\n",
    "            , 'Hazy, hot and humid': 'Hazy/Fog'\n",
    "            , 'Sunny Intervals': 'Clear'\n",
    "            , 'Partly Cloudy, Chance of Rain 80%': 'Rain'\n",
    "            , 'Mostly Clear. Gusting ot 14.': 'Windy'\n",
    "            , 'Mostly CLoudy': 'Cloudy'\n",
    "            , 'Snow Showers, 3 to 5 inches expected.': 'Snow'\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "     df = df.with_columns(pl.col(\"Weather\").replace(weather_dict)) # Standardizes the weather to a few main types\n",
    "\n",
    "     df = df.with_columns(             # Null handling - all null weather conditions for indoor stadiums are filled \"indoor\"\n",
    "                pl.when(pl.col(\"StadiumType\") == \"Indoor\")\n",
    "                .then(pl.col(\"Weather\").fill_null(\"Indoor\"))\n",
    "                .otherwise(pl.col(\"Weather\"))\n",
    "                .alias(\"Weather\")\n",
    "                )\n",
    "     \n",
    "     # For the non-indoor games with null values for weather, to maintain the percentage of games that were clear/cloudy, temperature was used as a divider, above and below 70 degrees\n",
    "     df = df.with_columns(\n",
    "                pl.when(pl.col(\"Temperature\") > 70)\n",
    "                .then(pl.col(\"Weather\").fill_null(\"Clear\"))\n",
    "                .otherwise(pl.col(\"Weather\"))\n",
    "                .alias(\"Weather\")\n",
    "                )\n",
    "     df = df.with_columns(pl.col(\"Weather\").fill_null(\"Cloudy\"))\n",
    "\n",
    "     print(f\"Looks like the weather has been cleared up.\")\n",
    "     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turf_cleaner(df):\n",
    "    import polars as pl\n",
    "\n",
    "    df = df.rename({\"Turf\": \"FieldType\"})\n",
    "\n",
    "    turf_dict = {\n",
    "        'Grass': 'Natural',\n",
    "        'Field Turf': 'Synthetic', \n",
    "        'Natural Grass': 'Natural',\n",
    "        'grass': 'Natural',\n",
    "        'Artificial': 'Synthetic',\n",
    "        'FieldTurf': 'Synthetic',\n",
    "        'DD GrassMaster': 'Synthetic',\n",
    "        'A-Turf Titan': 'Synthetic',\n",
    "        'UBU Sports Speed S5-M': 'Synthetic',\n",
    "        'UBU Speed Series S5-M': 'Synthetic',\n",
    "        'Artifical': 'Synthetic',\n",
    "        'UBU Speed Series-S5-M': 'Synthetic',\n",
    "        'FieldTurf 360': 'Synthetic',\n",
    "        'Natural grass': 'Natural',\n",
    "        'Field turf': 'Synthetic',\n",
    "        'Natural': 'Natural',\n",
    "        'Natrual Grass': 'Natural',\n",
    "        'Synthetic': 'Synthetic',\n",
    "        'Natural Grass ': 'Natural',\n",
    "        'Naturall Grass': 'Natural',\n",
    "        'FieldTurf360': 'Synthetic',\n",
    "        None: 'Natural' # The only field with null values is Miami Gardens, which has Natural\n",
    "        }\n",
    "    \n",
    "    df = df.with_columns(pl.col(\"FieldType\").replace(turf_dict))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancellation_cleaner(df):\n",
    "    \"\"\"\n",
    "    There are 44 rows that have no Game_Date, which correlate with games that were canceled. \n",
    "    This was verified by looking at the lineup of hometeam and visit team during those seasons.\n",
    "\n",
    "    Additionally, there are 10 rows that lack positions, numbers, or even an identifier to which \n",
    "    team the players were on, totalling 4 undocumented players. These rows will be removed as well.   \n",
    "    \"\"\"\n",
    "    import polars as pl\n",
    "\n",
    "    df = df.filter(pl.col(\"Game_Date\").is_not_null())\n",
    "    df = df.filter(pl.col(\"Position\").is_not_null()) # Removes 4 players and 10 rows where the position and player number were not recorded, none associated with injuries\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_splitter(df):\n",
    "    ''' \n",
    "    Splits the string column from Score_Home_Visiting into two numeric columns for each of the scores. It also creates a column that calculates the difference. \n",
    "    '''\n",
    "    import polars as pl # type: ignore\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"Score_Home_Visiting\").str.extract(r\"(\\d+)\\s*-\\s*(\\d+)\", 1).cast(pl.Int16).alias(\"Home_Score\")\n",
    "        , pl.col(\"Score_Home_Visiting\").str.extract(r\"(\\d+)\\s*-\\s*(\\d+)\", 2).cast(pl.Int16).alias(\"Visiting_Score\") # Find difference between scores\n",
    "        ])\n",
    "\n",
    "    df = df.with_columns([\n",
    "        (pl.col(\"Home_Score\") - pl.col(\"Visiting_Score\")).cast(pl.Int16).alias(\"Score_Difference\")\n",
    "        ])\n",
    "    \n",
    "    df = df.drop(\"Score_Home_Visiting\")\n",
    "    \n",
    "    print(f\"The scores have been fixed. Just not how Pete Rose would fix them.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_writer(df, new_file_name):\n",
    "    \"\"\"\n",
    "    Write table to local file as temporary until all cleaning and transformation is done.\n",
    "    \"\"\"\n",
    "    import polars as pl # type: ignore\n",
    "    import os\n",
    "       \n",
    "    path = 'F:/Data/Clean_Data'\n",
    "    full_path = f\"{path}/{new_file_name}.csv\"\n",
    "    \n",
    "    # Check if file exists\n",
    "    if os.path.exists(full_path):\n",
    "        os.remove(full_path)\n",
    "    \n",
    "    # Write new file\n",
    "    df.write_csv(full_path)\n",
    "    print(f\"New file has been written to {full_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_event_enum():\n",
    "#     \"\"\"\n",
    "#     Create an Enum for known events.\n",
    "#     \"\"\"\n",
    "#     import polars as pl # type: ignore\n",
    "\n",
    "#     return pl.Enum([\n",
    "#         \"ball_snap\"\n",
    "#       ,  \"drop_kick\"\n",
    "#       ,  \"end_path\"\n",
    "#       ,  \"extra_point\"\n",
    "#       ,  \"extra_point_attempt\"\n",
    "#       ,  \"extra_point_blocked\"\n",
    "#       ,  \"extra_point_fake\"\n",
    "#       ,  \"extra_point_missed\"\n",
    "#       ,  \"fair_catch\"\n",
    "#       ,  \"field_goal\"\n",
    "#       ,  \"field_goal_attempt\"\n",
    "#       ,  \"field_goal_blocked\"\n",
    "#       ,  \"field_goal_fake\"\n",
    "#       ,  \"field_goal_missed\"\n",
    "#       ,  \"field_goal_play\"\n",
    "#       ,  \"first_contact\"\n",
    "#       ,  \"free_kick\"\n",
    "#       ,  \"free_kick_play\"\n",
    "#       ,  \"fumble\"\n",
    "#       ,  \"fumble_defense_recovered\"\n",
    "#       ,  \"fumble_offense_recovered\"\n",
    "#       ,  \"handoff\"\n",
    "#       ,  \"huddle_break_offense\"\n",
    "#       ,  \"huddle_start_offense\"\n",
    "#       ,  \"kick_received\"\n",
    "#       ,  \"kick_recovered\"\n",
    "#       ,  \"kickoff\"\n",
    "#       ,  \"kickoff_land\"\n",
    "#       ,  \"kickoff_play\"\n",
    "#       ,  \"lateral\"\n",
    "#       ,  \"line_set\"\n",
    "#       ,  \"man_in_motion\"\n",
    "#       ,  \"onside_kick\"\n",
    "#       ,  \"out_of_bounds\"\n",
    "#       ,  \"pass_arrived\"\n",
    "#       ,  \"pass_forward\"\n",
    "#       ,  \"pass_lateral\"\n",
    "#       ,  \"pass_outcome_caught\"\n",
    "#       ,  \"pass_outcome_incomplete\"\n",
    "#       ,  \"pass_outcome_interception\"\n",
    "#       ,  \"pass_outcome_touchdown\"\n",
    "#       ,  \"pass_shovel\"\n",
    "#       ,  \"pass_tipped\"\n",
    "#       ,  \"penalty_accepted\"\n",
    "#       ,  \"penalty_declined\"\n",
    "#       ,  \"penalty_flag\"\n",
    "#       ,  \"play_action\"\n",
    "#       ,  \"play_submit\"\n",
    "#       ,  \"punt\"\n",
    "#       ,  \"punt_blocked\"\n",
    "#       ,  \"punt_downed\"\n",
    "#       ,  \"punt_fake\"\n",
    "#       ,  \"punt_land\"\n",
    "#       ,  \"punt_muffed\"\n",
    "#       ,  \"punt_play\"\n",
    "#       ,  \"punt_received\"\n",
    "#       ,  \"qb_kneel\"\n",
    "#       ,  \"qb_sack\"\n",
    "#       ,  \"qb_spike\"\n",
    "#       ,  \"qb_strip_sack\"\n",
    "#       ,  \"run\"\n",
    "#       ,  \"run_pass_option\"\n",
    "#       ,  \"safety\"\n",
    "#       ,  \"shift\"\n",
    "#       ,  \"snap_direct\"\n",
    "#       ,  \"tackle\"\n",
    "#       ,  \"timeout\"\n",
    "#       ,  \"timeout_away\"\n",
    "#       ,  \"timeout_booth_review\"\n",
    "#       ,  \"timeout_halftime\"\n",
    "#       ,  \"timeout_home\"\n",
    "#       ,  \"timeout_injury\"\n",
    "#       ,  \"timeout_quarter\"\n",
    "#       ,  \"timeout_tv\"\n",
    "#       ,  \"touchback\"\n",
    "#       ,  \"touchdown\"\n",
    "#       ,  \"two_minute_warning\"\n",
    "#       ,  \"two_point_conversion\"\n",
    "#       ,  \"two_point_play\"\n",
    "#       ,  \"xp_fake\"\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shrinker(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Optimize memory usage of a Polars dataframe for both categorical and numeric data.\n",
    "    \"\"\"\n",
    "    import polars as pl\n",
    "    import numpy as np\n",
    "\n",
    "    # Enable string cache to ensure consistent encoding\n",
    "    pl.enable_string_cache()\n",
    "\n",
    "    start_mem = df.estimated_size(\"mb\")\n",
    "    if verbose:\n",
    "        print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type in [pl.Int8, pl.Int16, pl.Int32, pl.Int64, pl.Float32, pl.Float64]:\n",
    "            # Handle missing values\n",
    "            if df[col].null_count() > 0:\n",
    "                c_min = df[col].min() if df[col].min() is not None else float('nan')\n",
    "                c_max = df[col].max() if df[col].max() is not None else float('nan')\n",
    "            else:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "            if col_type.is_integer():\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                    df = df.with_columns(pl.col(col).cast(pl.Int8))\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                    df = df.with_columns(pl.col(col).cast(pl.Int16))\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                    df = df.with_columns(pl.col(col).cast(pl.Int32))\n",
    "                else:\n",
    "                    df = df.with_columns(pl.col(col).cast(pl.Int64))\n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df = df.with_columns(pl.col(col).cast(pl.Float32))\n",
    "                else:\n",
    "                    df = df.with_columns(pl.col(col).cast(pl.Float64))\n",
    "\n",
    "        elif col_type == pl.Utf8:\n",
    "            if col != \"PlayKey\" and df[col].n_unique() / len(df) < 0.5:  # If less than 50% unique values\n",
    "                # Create an Enum type for the column\n",
    "                enum_type = pl.Enum(df[col].unique())\n",
    "                df = df.with_columns(pl.col(col).cast(enum_type))\n",
    "\n",
    "    end_mem = df.estimated_size(\"mb\")\n",
    "    if verbose:\n",
    "        print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
    "        print(f'Decreased by {100 * (start_mem - end_mem) / start_mem:.1f}%')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Primary Injury Cleaning Function #####\n",
    "def clean_injuries():\n",
    "    \"\"\"\n",
    "    Applies data cleaning to surface injury data and writes to 'qualitative_injuries' as a csv file \n",
    "    \"\"\"\n",
    "    analysis = \"injury\"\n",
    "    df = table_joiner(analysis) \n",
    "    df = injury_interpolator(df, analysis)\n",
    "    df = stadium_cleaner(df)\n",
    "    df = weather_cleaner(df)\n",
    "    df = data_shrinker(df)\n",
    "    # csv_writer(df, \"qualitative_injuries\")\n",
    "    # del df\n",
    "    print('Injuries have been cleaned and dressed.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Primary Concussion Cleaning Function #####\n",
    "def clean_concussions(): \n",
    "    \"\"\"\n",
    "    Applies data cleaning to surface injury data and writes to 'qualitative_injuries' as a csv file \n",
    "    \"\"\"\n",
    "    analysis = \"concussion\"\n",
    "    df = table_joiner(analysis)\n",
    "    df = injury_interpolator(df, analysis)\n",
    "    df = stadium_cleaner(df)\n",
    "    df = weather_cleaner(df)\n",
    "    df = turf_cleaner(df)\n",
    "    df = cancellation_cleaner(df)\n",
    "    df = score_splitter(df)\n",
    "    df = data_shrinker(df)\n",
    "    # csv_writer(df, \"qualitative_concussions\")\n",
    "    # del df\n",
    "\n",
    "    print('Concussions have been assessed and cleared for play.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataHandler import *\n",
    "from QualitativeCleaner import clean_concussions, clean_injuries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables are holding hands. How cute.\n",
      "Injury columns have been added.\n",
      "Someone managed to clean up those stadiums!\n",
      "Looks like the weather has been cleared up.\n",
      "Memory usage of dataframe is 14.00 MB\n",
      "Memory usage after optimization is: 10.92 MB\n",
      "Decreased by 22.0%\n",
      "New Parquet file has been written to F:/Data/Clean_Data/qualitative_injuries.parquet\n",
      "Injuries have been cleaned and dressed.\n"
     ]
    }
   ],
   "source": [
    "clean_injuries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables are holding hands. How cute.\n",
      "Injury columns have been added.\n",
      "Someone managed to clean up those stadiums!\n",
      "Looks like the weather has been cleared up.\n",
      "The scores have been fixed. Just not how Pete Rose would fix them.\n",
      "Memory usage of dataframe is 35.78 MB\n",
      "Memory usage after optimization is: 22.08 MB\n",
      "Decreased by 38.3%\n",
      "New Parquet file has been written to F:/Data/Clean_Data/qualitative_concussions.parquet\n",
      "Concussions have been assessed and cleared for play.\n"
     ]
    }
   ],
   "source": [
    "clean_concussions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataHandler import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 29)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PlayKey</th><th>GSISID</th><th>GameKey</th><th>PlayID</th><th>Position</th><th>Number</th><th>Role</th><th>Game_Date</th><th>YardLine</th><th>Quarter</th><th>Play_Type</th><th>Poss_Team</th><th>Game_Site</th><th>Start_Time</th><th>HomeTeamCode</th><th>VisitTeamCode</th><th>StadiumType</th><th>FieldType</th><th>Weather</th><th>Temperature</th><th>Player_Activity_Derived</th><th>Primary_Impact_Type</th><th>Primary_Partner_Activity_Derived</th><th>Primary_Partner_GSISID</th><th>OpponentKey</th><th>IsInjured</th><th>Home_Score</th><th>Visiting_Score</th><th>Score_Difference</th></tr><tr><td>str</td><td>i32</td><td>i16</td><td>i16</td><td>enum</td><td>enum</td><td>enum</td><td>enum</td><td>enum</td><td>i8</td><td>enum</td><td>enum</td><td>enum</td><td>enum</td><td>enum</td><td>enum</td><td>enum</td><td>enum</td><td>enum</td><td>f32</td><td>enum</td><td>enum</td><td>enum</td><td>i32</td><td>enum</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>&quot;28454-131-122&quot;</td><td>28454</td><td>131</td><td>122</td><td>&quot;OLB&quot;</td><td>&quot;55&quot;</td><td>&quot;PDL2&quot;</td><td>&quot;10/09/2016&quot;</td><td>&quot;CLV 32&quot;</td><td>1</td><td>&quot;Punt&quot;</td><td>&quot;CLV&quot;</td><td>&quot;Cleveland&quot;</td><td>&quot;13:00&quot;</td><td>&quot;CLV&quot;</td><td>&quot;NE&quot;</td><td>&quot;Outdoor&quot;</td><td>&quot;Natural&quot;</td><td>&quot;Clear&quot;</td><td>58.0</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>&quot;None&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;28495-264-272&quot;</td><td>28495</td><td>264</td><td>272</td><td>&quot;DE&quot;</td><td>&quot;94&quot;</td><td>&quot;PDR3&quot;</td><td>&quot;12/11/2016&quot;</td><td>&quot;JAX 14&quot;</td><td>1</td><td>&quot;Punt&quot;</td><td>&quot;JAX&quot;</td><td>&quot;Jacksonville&quot;</td><td>&quot;13:00&quot;</td><td>&quot;JAX&quot;</td><td>&quot;MIN&quot;</td><td>&quot;Outdoor&quot;</td><td>&quot;Natural&quot;</td><td>&quot;Clear&quot;</td><td>71.0</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>&quot;None&quot;</td><td>0</td><td>0</td><td>3</td><td>-3</td></tr><tr><td>&quot;32190-367-3608&quot;</td><td>32190</td><td>367</td><td>3608</td><td>&quot;TE&quot;</td><td>&quot;82&quot;</td><td>&quot;PRG&quot;</td><td>&quot;08/26/2017&quot;</td><td>&quot;ARZ 17&quot;</td><td>4</td><td>&quot;Punt&quot;</td><td>&quot;ARZ&quot;</td><td>&quot;Atlanta&quot;</td><td>&quot;19:00&quot;</td><td>&quot;ATL&quot;</td><td>&quot;ARZ&quot;</td><td>&quot;Indoor&quot;</td><td>&quot;Synthetic&quot;</td><td>&quot;Indoor&quot;</td><td>70.0</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>&quot;None&quot;</td><td>0</td><td>6</td><td>24</td><td>-18</td></tr><tr><td>&quot;29529-546-2191&quot;</td><td>29529</td><td>546</td><td>2191</td><td>&quot;CB&quot;</td><td>&quot;24&quot;</td><td>&quot;VLo&quot;</td><td>&quot;11/16/2017&quot;</td><td>&quot;TEN 25&quot;</td><td>2</td><td>&quot;Punt&quot;</td><td>&quot;TEN&quot;</td><td>&quot;Pittsburgh&quot;</td><td>&quot;20:25&quot;</td><td>&quot;PIT&quot;</td><td>&quot;TEN&quot;</td><td>&quot;Outdoor&quot;</td><td>&quot;Natural&quot;</td><td>&quot;Cloudy&quot;</td><td>40.0</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>&quot;None&quot;</td><td>0</td><td>13</td><td>7</td><td>6</td></tr><tr><td>&quot;30181-93-914&quot;</td><td>30181</td><td>93</td><td>914</td><td>&quot;TE&quot;</td><td>&quot;84&quot;</td><td>&quot;PLW&quot;</td><td>&quot;09/18/2016&quot;</td><td>&quot;IND 30&quot;</td><td>1</td><td>&quot;Punt&quot;</td><td>&quot;IND&quot;</td><td>&quot;Denver&quot;</td><td>&quot;14:25&quot;</td><td>&quot;DEN&quot;</td><td>&quot;IND&quot;</td><td>&quot;Outdoor&quot;</td><td>&quot;Natural&quot;</td><td>&quot;Clear&quot;</td><td>85.0</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>&quot;None&quot;</td><td>0</td><td>3</td><td>3</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 29)\n",
       "┌─────────────┬────────┬─────────┬────────┬───┬───────────┬────────────┬─────────────┬─────────────┐\n",
       "│ PlayKey     ┆ GSISID ┆ GameKey ┆ PlayID ┆ … ┆ IsInjured ┆ Home_Score ┆ Visiting_Sc ┆ Score_Diffe │\n",
       "│ ---         ┆ ---    ┆ ---     ┆ ---    ┆   ┆ ---       ┆ ---        ┆ ore         ┆ rence       │\n",
       "│ str         ┆ i32    ┆ i16     ┆ i16    ┆   ┆ i8        ┆ i8         ┆ ---         ┆ ---         │\n",
       "│             ┆        ┆         ┆        ┆   ┆           ┆            ┆ i8          ┆ i8          │\n",
       "╞═════════════╪════════╪═════════╪════════╪═══╪═══════════╪════════════╪═════════════╪═════════════╡\n",
       "│ 28454-131-1 ┆ 28454  ┆ 131     ┆ 122    ┆ … ┆ 0         ┆ 0          ┆ 0           ┆ 0           │\n",
       "│ 22          ┆        ┆         ┆        ┆   ┆           ┆            ┆             ┆             │\n",
       "│ 28495-264-2 ┆ 28495  ┆ 264     ┆ 272    ┆ … ┆ 0         ┆ 0          ┆ 3           ┆ -3          │\n",
       "│ 72          ┆        ┆         ┆        ┆   ┆           ┆            ┆             ┆             │\n",
       "│ 32190-367-3 ┆ 32190  ┆ 367     ┆ 3608   ┆ … ┆ 0         ┆ 6          ┆ 24          ┆ -18         │\n",
       "│ 608         ┆        ┆         ┆        ┆   ┆           ┆            ┆             ┆             │\n",
       "│ 29529-546-2 ┆ 29529  ┆ 546     ┆ 2191   ┆ … ┆ 0         ┆ 13         ┆ 7           ┆ 6           │\n",
       "│ 191         ┆        ┆         ┆        ┆   ┆           ┆            ┆             ┆             │\n",
       "│ 30181-93-91 ┆ 30181  ┆ 93      ┆ 914    ┆ … ┆ 0         ┆ 3          ┆ 3           ┆ 0           │\n",
       "│ 4           ┆        ┆         ┆        ┆   ┆           ┆            ┆             ┆             │\n",
       "└─────────────┴────────┴─────────┴────────┴───┴───────────┴────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader('qualitative_concussions').head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 14)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>PlayKey</th><th>Position</th><th>StadiumType</th><th>FieldType</th><th>Temperature</th><th>Weather</th><th>PlayType</th><th>BodyPart</th><th>DM_M1</th><th>DM_M7</th><th>DM_M28</th><th>DM_M42</th><th>IsInjured</th><th>IsSevere</th></tr><tr><td>str</td><td>enum</td><td>enum</td><td>enum</td><td>i16</td><td>enum</td><td>enum</td><td>enum</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>&quot;26624-1-1&quot;</td><td>&quot;QB&quot;</td><td>&quot;Outdoor&quot;</td><td>&quot;Synthetic&quot;</td><td>63</td><td>&quot;Clear&quot;</td><td>&quot;Pass&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;26624-1-2&quot;</td><td>&quot;QB&quot;</td><td>&quot;Outdoor&quot;</td><td>&quot;Synthetic&quot;</td><td>63</td><td>&quot;Clear&quot;</td><td>&quot;Pass&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;26624-1-3&quot;</td><td>&quot;QB&quot;</td><td>&quot;Outdoor&quot;</td><td>&quot;Synthetic&quot;</td><td>63</td><td>&quot;Clear&quot;</td><td>&quot;Rush&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;26624-1-4&quot;</td><td>&quot;QB&quot;</td><td>&quot;Outdoor&quot;</td><td>&quot;Synthetic&quot;</td><td>63</td><td>&quot;Clear&quot;</td><td>&quot;Rush&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&quot;26624-1-5&quot;</td><td>&quot;QB&quot;</td><td>&quot;Outdoor&quot;</td><td>&quot;Synthetic&quot;</td><td>63</td><td>&quot;Clear&quot;</td><td>&quot;Pass&quot;</td><td>&quot;No_Injury&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 14)\n",
       "┌───────────┬──────────┬─────────────┬───────────┬───┬────────┬────────┬───────────┬──────────┐\n",
       "│ PlayKey   ┆ Position ┆ StadiumType ┆ FieldType ┆ … ┆ DM_M28 ┆ DM_M42 ┆ IsInjured ┆ IsSevere │\n",
       "│ ---       ┆ ---      ┆ ---         ┆ ---       ┆   ┆ ---    ┆ ---    ┆ ---       ┆ ---      │\n",
       "│ str       ┆ enum     ┆ enum        ┆ enum      ┆   ┆ i8     ┆ i8     ┆ i8        ┆ i8       │\n",
       "╞═══════════╪══════════╪═════════════╪═══════════╪═══╪════════╪════════╪═══════════╪══════════╡\n",
       "│ 26624-1-1 ┆ QB       ┆ Outdoor     ┆ Synthetic ┆ … ┆ 0      ┆ 0      ┆ 0         ┆ 0        │\n",
       "│ 26624-1-2 ┆ QB       ┆ Outdoor     ┆ Synthetic ┆ … ┆ 0      ┆ 0      ┆ 0         ┆ 0        │\n",
       "│ 26624-1-3 ┆ QB       ┆ Outdoor     ┆ Synthetic ┆ … ┆ 0      ┆ 0      ┆ 0         ┆ 0        │\n",
       "│ 26624-1-4 ┆ QB       ┆ Outdoor     ┆ Synthetic ┆ … ┆ 0      ┆ 0      ┆ 0         ┆ 0        │\n",
       "│ 26624-1-5 ┆ QB       ┆ Outdoor     ┆ Synthetic ┆ … ┆ 0      ┆ 0      ┆ 0         ┆ 0        │\n",
       "└───────────┴──────────┴─────────────┴───────────┴───┴────────┴────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injuries = data_loader('qualitative_injuries')\n",
    "injuries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/3.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
